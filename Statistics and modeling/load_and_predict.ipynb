{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction #\n",
    "\n",
    "After a first check on the data, using ordinal regressions and linear regressions, we can add new variables we've seen can help with prediction and use them with more complex models such as tree based or mlp models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import feature_selection\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error,roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression, PoissonRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, IsolationForest\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import pickle\n",
    "from difflib import SequenceMatcher\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def third_largest(row):\n",
    "    sorted_row = sorted(row, reverse=True)\n",
    "    return sorted_row[2] if len(sorted_row) >= 3 else None\n",
    "\n",
    "def third_smallest(row):\n",
    "    sorted_row = sorted(row)\n",
    "    return sorted_row[2] if len(sorted_row) >= 3 else None\n",
    "\n",
    "def get_data_cols(df, att, prefix):\n",
    "    '''\n",
    "    Gets an attribute, and adds columns to show mean, max, min and sd (ignoring zeros) for the first num_players players.\n",
    "\n",
    "    Parameters:\n",
    "    df : The dataframe\n",
    "    att: which attribute (e.g., Weight)\n",
    "    prefix: HomePlayer or AwayPlayer\n",
    "    '''\n",
    "\n",
    "    player_weight_cols = [col for col in df.columns if col.startswith(f\"{prefix}\") and col.endswith(f\"_{att}\")]\n",
    "    att = att.replace('(', ' ')\n",
    "    if not player_weight_cols:\n",
    "        print('no col with', att)\n",
    "        return df\n",
    "\n",
    "    # Select only the columns corresponding to the first num_players players\n",
    "    player_weight_cols_subset = player_weight_cols[:11]  # Selecting the first 11 players\n",
    "\n",
    "    # Replace zeros with NaN\n",
    "    df[player_weight_cols_subset] = df[player_weight_cols_subset].replace(0, np.nan)\n",
    "\n",
    "\n",
    "    if(att == 'Overall'):\n",
    "        df[f\"{prefix}_{att}_max\"] = df[player_weight_cols_subset].max(axis=1, skipna=True)\n",
    "        df[f\"{prefix}_{att}_min\"] = df[player_weight_cols_subset].min(axis=1, skipna=True)\n",
    "        df[f\"{prefix}_{att}_sd\"] = df[player_weight_cols_subset].std(axis=1, skipna=True)\n",
    "        df[f\"{prefix}_{att}_mean\"] = df[player_weight_cols_subset].mean(axis=1, skipna=True)\n",
    "        df[f\"{prefix}_{att}_mean_ln\"] = np.log(df[player_weight_cols_subset]).mean(axis=1, skipna=True)\n",
    "        df[f\"{prefix}_{att}_mean_sqrt\"] = np.sqrt(df[player_weight_cols_subset]).mean(axis=1, skipna=True)\n",
    "        df[f\"{prefix}_3rd_best\"] = df[player_weight_cols_subset].apply(third_largest, axis=1)\n",
    "        df[f\"{prefix}_3rd_worst\"] = df[player_weight_cols_subset].apply(third_smallest, axis=1)\n",
    "\n",
    "\n",
    "    # For bench players (i >= 12)\n",
    "    bench_weight_cols = player_weight_cols[11:]  # Selecting players from index 12 and onwards\n",
    "\n",
    "    # Replace zeros with NaN for bench players\n",
    "    df[bench_weight_cols] = df[bench_weight_cols].replace(0, np.nan)\n",
    "\n",
    "    if(' ' in att): # 2 worded attributes so instead of dribbling total we will have dribbling\n",
    "        df[f\"{prefix}_bench_{att.split()[0]}_mean\"] = df[bench_weight_cols].mean(axis=1, skipna=True)\n",
    "        df[f\"{prefix}_{att.split()[0]}_mean\"] = df[player_weight_cols_subset].mean(axis=1, skipna=True)\n",
    "\n",
    "    else:\n",
    "        df[f\"{prefix}_bench_{att}_mean\"] = df[bench_weight_cols].mean(axis=1, skipna=True)\n",
    "        df[f\"{prefix}_{att}_mean\"] = df[player_weight_cols_subset].mean(axis=1, skipna=True)\n",
    "\n",
    "    if(att == 'Overall'):\n",
    "        df[f\"{prefix}_bench_{att}_max\"] = df[bench_weight_cols].max(axis=1, skipna=True)\n",
    "        df[f\"{prefix}_bench_{att}_min\"] = df[bench_weight_cols].min(axis=1, skipna=True)\n",
    "        df[f\"{prefix}_bench_{att}_sd\"] = df[bench_weight_cols].std(axis=1, skipna=True)\n",
    "        df[f\"{prefix}_bench_{att}_mean\"] = df[player_weight_cols_subset].mean(axis=1, skipna=True)\n",
    "\n",
    "    return df\n",
    "def find_most_similar_name(target_name, names_list, threshold=0.25):\n",
    "    similarities = [(other_name, SequenceMatcher(None, target_name, other_name).ratio()) for other_name in names_list]\n",
    "    if (len(similarities) == 0):\n",
    "        return None, None\n",
    "    most_similar_name, similarity_score = max(similarities, key=lambda x: x[1])\n",
    "    \n",
    "    if similarity_score >= threshold:\n",
    "        #print('found player '+most_similar_name+\" with a score of \"+str(similarity_score))\n",
    "        return most_similar_name, similarity_score\n",
    "    else:\n",
    "        print(\"didn't find\", target_name)\n",
    "        return None, None\n",
    "def find_player(player_name, club_name,  df, attributes):\n",
    "    #first we filter by club name\n",
    "    temp = df[df['Club Name'] == club_name]\n",
    "\n",
    "    #Now we find the player\n",
    "    sim_name, full_score = find_most_similar_name(player_name, temp['Full Name'])\n",
    "    sim_nickname, short_score = find_most_similar_name(player_name, temp['Known As'])\n",
    "    if sim_name: # there is a full name\n",
    "        ## if there is a nickname we have to check\n",
    "        if sim_nickname and full_score > short_score:\n",
    "            return temp[temp['Full Name'] == sim_name].iloc[0][attributes]\n",
    "        elif sim_nickname:\n",
    "            return temp[temp['Known As'] == sim_nickname].iloc[0][attributes]\n",
    "        return temp[temp['Full Name'] == sim_name].iloc[0][attributes]\n",
    "    if sim_nickname: # if there is a nickname but no full name\n",
    "        return temp[temp['Known As'] == sim_nickname].iloc[0][attributes]\n",
    "    return None\n",
    "\n",
    "\n",
    "def ratings_col(df, att_df):\n",
    "    '''\n",
    "    puts for every player their 'Overall', 'Age', 'Height(in cm)', 'Weight(in kg)'\n",
    "    for each player i we will have the column\n",
    "    HomePlayeri (if the player is on the home team)\n",
    "    AwayPlayeri (if the player is on the away team)\n",
    "    and we will use the home_team_name or away_team_name and the full name as the key (we will use find_player(player_name, club_name,  df, attributes))\n",
    "    '''\n",
    "\n",
    "    attributes = [ 'Overall', 'Age', 'Height(in cm)', 'Weight(in kg)']\n",
    "    # Iterate through each player column\n",
    "    for i in range(1, 21):\n",
    "\n",
    "        home_col = f'HomePlayer{i}'\n",
    "        away_col = f'AwayPlayer{i}'\n",
    "        if home_col in df.columns or away_col in df.columns:\n",
    "            # Add columns for home team players\n",
    "            for att in attributes:\n",
    "                df[home_col + \"_\" + att] = df.apply(\n",
    "                    lambda row: 0 if pd.isna(row[home_col]) else\n",
    "                    (find_player(row[home_col], row['home_team_name'], att_df, attributes)[att]\n",
    "                    if find_player(row[home_col], row['home_team_name'], att_df, attributes) is not None else None),\n",
    "                    axis=1\n",
    "                )\n",
    "\n",
    "            for att in attributes:\n",
    "                df[away_col + \"_\" + att] = df.apply(\n",
    "                    lambda row: 0 if pd.isna(row[away_col]) else\n",
    "                    (find_player(row[away_col], row['away_team_name'], att_df, attributes)[att]\n",
    "                    if find_player(row[away_col], row['away_team_name'], att_df, attributes) is not None else None),\n",
    "                    axis=1\n",
    "                )\n",
    "def replace_nas(df):\n",
    "    '''\n",
    "    gets df, goes to the Age column and replaces None with 18, and replaces Weight(in kg) and Height(in cm) with the mean, and overall with the min value\n",
    "    '''\n",
    "\n",
    "    # 'Dribbling Total', 'Pace Total', 'Defending Total', 'Shooting Total', 'Physicality Total', 'Passing Total' our new fatures\n",
    "    attributes = ['Overall','Height(in cm)', 'Weight(in kg)']\n",
    "    # First, deal with the None values\n",
    "    for i in range(1,21):\n",
    "        home_col = f'HomePlayer{i}'\n",
    "        away_col = f'AwayPlayer{i}'\n",
    "        if home_col in df.columns:\n",
    "            # Age assumption\n",
    "            df[home_col+\"_Age\"].fillna(18, inplace=True)\n",
    "\n",
    "            for att  in attributes: \n",
    "                non_zero_col = df[home_col+'_'+att].replace(0, None)\n",
    "                df[home_col+'_'+att].fillna(non_zero_col.min())\n",
    "        if away_col in df.columns:\n",
    "            # Age assumption\n",
    "            df[away_col+\"_Age\"].fillna(18, inplace=True)\n",
    "\n",
    "            for att  in attributes: \n",
    "                non_zero_col = df[away_col+'_'+att].replace(0, None)\n",
    "                df[away_col+'_'+att].fillna(non_zero_col.min())\n",
    "            # df[home_col+\"_Age\"].fillna(18, inplace=True)\n",
    "            \n",
    "            # # dealing with some ratings\n",
    "\n",
    "            # df[home_col+\"_Total\"].fillna(18, inplace=True)\n",
    "            # df[home_col+\"_Dribbling Total\"].fillna(df[home_col+\"_Dribbling Total\"].replace(0,None).min(), inplace=True)\n",
    "            # df[home_col+\"_Defending Total\"].fillna(df[home_col+\"_Defending Total\"].replace(0,None).min(), inplace=True)\n",
    "            # df[home_col+\"_Shooting Total\"].fillna(df[home_col+\"_Shooting Total\"].replace(0,None).min(), inplace=True)\n",
    "            # df[home_col+\"_Physicality Total\"].fillna(df[home_col+\"_Physicality Total\"].replace(0,None).min(), inplace=True)\n",
    "            # df[home_col+\"_Pace Total\"].fillna(df[home_col+\"_Pace Total\"].replace(0,None).min(), inplace=True)\n",
    "\n",
    "            # # Build assumption (ignoring zeros)\n",
    "            # non_zero_weights = df[home_col+\"_Weight(in kg)\"].replace(0, None)\n",
    "            # non_zero_heights = df[home_col+\"_Height(in cm)\"].replace(0, None)\n",
    "            # non_zero_overall = df[home_col+\"_Overall\"].replace(0, None)\n",
    "            # df[home_col+\"_Weight\"].fillna(non_zero_weights.mean(), inplace=True)\n",
    "            # df[home_col+\"_Height\"].fillna(non_zero_heights.mean(), inplace=True)\n",
    "            \n",
    "            \n",
    "            # # Ratings assumption\n",
    "            # df[home_col+\"_Overall\"].fillna(non_zero_overall.min(), inplace=True)\n",
    "            \n",
    "            # # And for away\n",
    "            # # Age assumption\n",
    "            # df[away_col+\"_Age\"].fillna(18, inplace=True)\n",
    "\n",
    "            # df[away_col+\"_Total\"].fillna(18, inplace=True)\n",
    "            # df[away_col+\"_Dribbling Total\"].fillna(df[away_col+\"_Dribbling Total\"].replace(0,None).min(), inplace=True)\n",
    "            # df[away_col+\"_Defending Total\"].fillna(df[away_col+\"_Defending Total\"].replace(0,None).min(), inplace=True)\n",
    "            # df[away_col+\"_Shooting Total\"].fillna(df[away_col+\"_Shooting Total\"].replace(0,None).min(), inplace=True)\n",
    "            # df[away_col+\"_Physicality Total\"].fillna(df[away_col+\"_Physicality Total\"].replace(0,None).min(), inplace=True)\n",
    "            # df[away_col+\"_Pace Total\"].fillna(df[away_col+\"_Pace Total\"].replace(0,None).min(), inplace=True)\n",
    "\n",
    "            # # Build assumption (ignoring zeros)\n",
    "            # non_zero_weights_away = df[away_col+\"_Weight\"].replace(0, None)\n",
    "            # non_zero_heights_away = df[away_col+\"_Height\"].replace(0, None)\n",
    "            # non_zero_overall_away = df[away_col+\"_Overall\"].replace(0, None)\n",
    "            # df[away_col+\"_Weight\"].fillna(non_zero_weights_away.mean(), inplace=True)\n",
    "            # df[away_col+\"_Height\"].fillna(non_zero_heights_away.mean(), inplace=True)\n",
    "            \n",
    "            # # Ratings assumption\n",
    "            # df[away_col+\"_Overall\"].fillna(non_zero_overall_away.min(), inplace=True)\n",
    "            \n",
    "\n",
    "    # Dealing with zero values\n",
    "    for i in range(1, 21):\n",
    "        home_col = f'HomePlayer{i}'\n",
    "        away_col = f'AwayPlayer{i}'\n",
    "        if home_col in df.columns:\n",
    "            for att in attributes:\n",
    "                df[home_col+\"_\"+att].replace(0, None, inplace=True)\n",
    "        if away_col in df.columns:\n",
    "            for att in attributes:\n",
    "                df[away_col+\"_\"+att].replace(0, None, inplace=True)\n",
    "     \n",
    "def set_season_cols(columns, season):\n",
    "    for c in season.columns:\n",
    "        for att in ['Overall', 'Age', 'Height(in cm)', 'Weight(in kg)']:\n",
    "            if att in c:\n",
    "                columns.append(c)\n",
    "    \n",
    "\n",
    "\n",
    "def pipeline(train_arr, fifa):\n",
    "    train_df = pd.read_csv(train_arr, encoding='latin1')\n",
    "    ratings_df = pd.read_csv(fifa,encoding='latin1')\n",
    "    ratings_df.rename(columns={'long_name' : 'Full Name', 'height_cm':'Height(in cm)',\n",
    "                          'weight_kg' : 'Weight(in kg)',\n",
    "                          'age' : 'Age','club_name' :\"Club Name\",\n",
    "                          'overall' : 'Overall', 'dribbling' : 'Dribbling Total',\n",
    "                          'pace' : 'Pace Total', 'defending' : \"Defending Total\" ,\n",
    "                          \"shooting\" : 'Shooting Total', 'physic' : 'Physicality Total',\n",
    "                          'passing' : \"Passing Total\", 'short_name' : 'Known As'},inplace=True)\n",
    "    #first we replace the names with the numbers\n",
    "    # fix_html_col(ratings_df, 'away_fromation')\n",
    "    # fix_html_col(ratings_df, 'home_formation')\n",
    "\n",
    "    # Define a dictionary\n",
    "    names_fix = {'Man Utd': \"Manchester United\",\n",
    "             \"Man City\": 'Manchester City',\n",
    "             \"West Ham\": \"West Ham United\",\n",
    "             \"Nott'm Forest\": \"Nottingham Forest\",\n",
    "             'Spurs': \"Tottenham Hotspur\",\n",
    "             'Wolves': \"Wolverhampton Wanderers\",\n",
    "             \"Brighton and Hove Albion\": \"Brighton & Hove Albion\",\n",
    "             \"Bournemouth\": \"AFC Bournemouth\",\n",
    "             'Newcastle': 'Newcastle United',\n",
    "             'Leicester': 'Leicester City',\n",
    "             'Leeds': \"Leeds United\",\n",
    "             'Huddersfield' : 'Huddersfield Town',\n",
    "             'Swansea' : 'Swansea City',\n",
    "             'Cardiff': 'Cardiff City',\n",
    "             'Norwich' : 'Norwich City',\n",
    "             'Stoke' : 'Stoke City',\n",
    "             'West Brom' : 'West Bromwich Albion',\n",
    "             'Hull' : 'Hull City',\n",
    "             'QPR' : 'Queens Park Rangers',\n",
    "             'Sheffield Utd' : 'Sheffield United'}\n",
    "    \n",
    " \n",
    "    for key, val in names_fix.items():\n",
    "        train_df['home_team_name'].replace(key, val, inplace=True)\n",
    "        train_df['away_team_name'].replace(key, val, inplace=True)\n",
    "    print(\"Finished Loading test\")\n",
    "    # print(train_df.columns)\n",
    "    att_list = ['Overall']\n",
    "    numerical_cols = []\n",
    "    statistic_list = ['mean', 'min', 'max', 'sd', 'median', '3rd_best', '3rd_worst']\n",
    "    #statistic_list = ['mean' ,'sd']\n",
    "    cat_cols=['home_team_name', 'away_team_name', 'home_formation', 'away_fromation']\n",
    "\n",
    "    \n",
    "    att_list = ['Overall', 'Age', 'Height(in cm)', 'Weight(in kg)']\n",
    "    for att in att_list:\n",
    "        if att not in ratings_df.columns:\n",
    "            print('fix',att)\n",
    "    \n",
    "    # Sanity Check\n",
    "    ratings_df = ratings_df[['Full Name', 'Club Name', 'Known As']+ att_list]\n",
    "    ratings_col(train_df, ratings_df)\n",
    "\n",
    "    replace_nas(train_df)\n",
    "    train_df['Matchweek'] = train_df['Matchweek'].str.split(' ').str[1].astype(int)\n",
    "\n",
    "    final_cols = ['home_score', 'home_team_name', 'away_score', 'away_team_name', 'away_fromation', 'home_formation', 'home_GD_prior', 'away_GD_prior', 'home_Points_prior', 'away_Points_prior', 'Matchweek']\n",
    "    set_season_cols(final_cols, train_df)\n",
    "\n",
    "    \n",
    "    #binary_cols = ['Home_Adv_Team', 'Strong_Away'] ## From ar\n",
    "    \n",
    "\n",
    "    for att in att_list:\n",
    "        get_data_cols(train_df, att, prefix='HomePlayer')\n",
    "        get_data_cols(train_df, att, prefix='AwayPlayer')\n",
    "    \n",
    "    for col in train_df.columns:\n",
    "        for s in statistic_list:\n",
    "            if s in col:\n",
    "                numerical_cols.append(col)\n",
    "\n",
    "    cat_cols=['Unnamed: 0', 'home_team_name', 'away_team_name', 'home_formation', \n",
    "              'away_fromation', 'home_GD_prior', \n",
    "              'home_Points_prior', 'home_GD_form', 'home_Points_form', 'home_GD_form_pw', 'home_Points_form_pw',\n",
    "                'away_GD_prior', 'away_Points_prior', 'away_GD_form', 'away_GD_form_pw', 'away_Points_form_pw',\n",
    "                'away_Points_form','Matchweek', 'home_points_to_championship',\n",
    "                'home_points_to_ucl','home_points_to_rel','away_points_to_championship',\n",
    "                'away_points_to_ucl','away_points_to_rel', 'home_match_importance', 'away_match_importance', 'B365A', 'B365D', 'B365H', 'HtA']\n",
    "    return train_df[numerical_cols + cat_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skellam\n",
    "\n",
    "def extract_poisson_probas(home_pred, away_pred):\n",
    "    '''\n",
    "    creates a probability matrix according to the regression\n",
    "\n",
    "    Parameters:\n",
    "    home_pred: expected home score\n",
    "    away_pred: expected away score\n",
    "    '''\n",
    "\n",
    "    probability_matrix = np.zeros((len(home_pred), 3))  # 3 columns (-1, 0, 1 probabilities)\n",
    "    \n",
    "    for i in range(len(home_pred)):\n",
    "        # Check for NaN values and skip the calculation if found\n",
    "        if np.isnan(home_pred[i]) or np.isnan(away_pred[i]):\n",
    "            continue\n",
    "\n",
    "        home_rounded = home_pred[i]\n",
    "        away_rounded = away_pred[i]\n",
    "                \n",
    "        probability_matrix[i, 0] = skellam.cdf(-1, home_rounded, away_rounded)\n",
    "        probability_matrix[i, 1] = skellam.pmf(0, home_rounded, away_rounded)\n",
    "        probability_matrix[i, 2] = skellam.sf(0, home_rounded, away_rounded)\n",
    "        if(probability_matrix[i, 0] == np.nan or probability_matrix[i, 1] == np.nan or probability_matrix[i, 2] == np.nan):\n",
    "            print(\"NAN PRODUCED IN INDEX\", i)\n",
    "        \n",
    "    return probability_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-78-e2afba917b38>, line 45)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-78-e2afba917b38>\"\u001b[1;36m, line \u001b[1;32m45\u001b[0m\n\u001b[1;33m    \"Best bet by sqrt (0 - away, 1 - draw, 2 - home team)\": np.argmax(probas*np.sqrt(np.asarray(train[['B365A', 'B365D', 'B365H']])),\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def get_lineups_and_predict(match, fifa):\n",
    "    train = pipeline(match, fifa)\n",
    "    home_reg = XGBRegressor()\n",
    "    home_reg.load_model(\"home_regression.json\")\n",
    "    features = home_reg.get_booster().feature_names\n",
    "    away_reg = XGBRegressor()\n",
    "    away_reg.load_model(\"away_regression.json\")\n",
    "    fixtures = list(train['home_team_name'] + ' V '+train['away_team_name'])\n",
    "    print(fixtures)\n",
    "    #pre processing\n",
    "    train.drop(['home_formation', 'away_fromation'], axis=1, inplace=True)\n",
    "    train[\"Home_min_max\"] = train['HomePlayer_Overall_max'] * train['HomePlayer_Overall_min']\n",
    "    train['Away_min_max'] = train['AwayPlayer_Overall_max'] * train['AwayPlayer_Overall_min']\n",
    "    with open('encoder', 'rb') as file:\n",
    "        enc = pickle.load(file)\n",
    "    \n",
    "    # One-hot encode 'home_team_name'\n",
    "    encoded = enc.transform(train[['home_team_name', 'away_team_name']])\n",
    "    encoded_df = pd.DataFrame(encoded, columns=enc.get_feature_names_out(['home_team_name', 'away_team_name']))\n",
    "    train = pd.concat([encoded_df, train], axis=1)\n",
    "\n",
    "    train.drop(['home_team_name', 'away_team_name'], axis=1, inplace=True)\n",
    "    train = train[features]\n",
    "    for col in train.columns:\n",
    "        train[col] = train[col].astype(float)\n",
    "    home_pred = home_reg.predict(train)\n",
    "    away_pred = away_reg.predict(train)\n",
    "    print(\"Home expected goals:\", home_pred)\n",
    "    print(\"Away expected goals:\", away_pred)\n",
    "    probas = extract_poisson_probas(home_pred, away_pred)\n",
    "    print('Expected outcomes:')\n",
    "    outcomes = probas * np.asarray(train[['B365A', 'B365D', 'B365H']])\n",
    "    print(\"win outcomes\", outcomes[:,2])\n",
    "    print(\"tie outcomes\", outcomes[:,1])\n",
    "    print(\"loss outcomes\", outcomes[:,0])\n",
    "    df = pd.DataFrame({'Fixture' : fixtures,\n",
    "                       \"Home Expected Goals\": home_pred,\n",
    "                       \"Away Expected Goals\": away_pred,\n",
    "                       'Home Expected' : outcomes[:, 2],\n",
    "                       'Draw Expected' : outcomes[:, 1],\n",
    "                       'Away Expected' : outcomes[:, 0],\n",
    "                       \"Home Proba\" : probas[:, 2],\n",
    "                       \"Away Proba\" : probas[:, 0],\n",
    "                       \"Draw Probas\" : probas[:, 1],\n",
    "                       \"Best bet by sqrt (0 - away, 1 - draw, 2 - home team)\": np.argmax(probas*np.sqrt(np.asarray(train[['B365A', 'B365D', 'B365H']])), \n",
    "                       axis = 1),\n",
    "                       \"Best bet by ln  (0 - away, 1 - draw, 2 - home team)\": np.argmax(probas*np.log(np.asarray(train[['B365A', 'B365D', 'B365H']])), \n",
    "                       axis = 1)})\n",
    "    df.to_csv(\"predictions.csv\")\n",
    "    return probas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-66-f0c51175048c>:217: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ratings_df = pd.read_csv(fifa,encoding='latin1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Loading test\n",
      "['Sheffield United V Burnley', 'Luton V Brentford', 'Wolverhampton Wanderers V Arsenal', 'Everton V Nottingham Forest', 'Aston Villa V AFC Bournemouth', 'Crystal Palace V West Ham United', 'Fulham V Liverpool']\n",
      "Home expected goals: [1.0903704 1.3886279 0.8556589 1.3109288 1.9698511 1.3338624 1.1285495]\n",
      "Away expected goals: [1.2843288  1.2843288  1.8714763  0.98008406 0.98008406 1.0520478\n",
      " 1.8714763 ]\n",
      "Expected outcomes:\n",
      "win outcomes [0.84905542 1.26236791 1.66454752 0.90563166 1.11749969 0.88400343\n",
      " 1.19388323]\n",
      "tie outcomes [0.99615748 0.97230163 1.10166222 0.97774261 0.85600171 1.0279774\n",
      " 1.01412031]\n",
      "loss outcomes [1.00162031 0.72708214 0.81557303 1.0039443  0.6550045  1.00181514\n",
      " 0.85915675]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.40882462, 0.27671041, 0.31446497],\n",
       "       [0.34622959, 0.25928043, 0.39448997],\n",
       "       [0.6132128 , 0.22033244, 0.16645475],\n",
       "       [0.27887342, 0.27935503, 0.44177154],\n",
       "       [0.1819457 , 0.21400043, 0.60405389],\n",
       "       [0.29465151, 0.27412731, 0.43122118],\n",
       "       [0.5472336 , 0.22536007, 0.22740633]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lineups_and_predict('format.csv', 'fifa_season.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
